---
title: "Contrast Method for Literature-Based Discovery: Full Replication"
author: "Erwan Moreau"
date: "May 2021"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

This is the documentation of the companion code for the paper **TODO**, which presents a novel approach for Literature-Based Discovery. The approach relies on contrasting different "views" of the data, the data being the biomedical literature (Medline and PubMed Central). The experiments use 8 relations which correspond to past discoveries in the domain of Neurodegenerative Diseases (NDs).

- The paper can be found at **TODO**
- The code is available at https://github.com/erwanm/lbd-contrast



## Data Requirements

Two options are possible: the "short reproducibility study" proposes to use the exact same preprocessed dataset as described in the paper, whereas the "full replication" described in this document offers more flexibility but requires much more computing resources (access to a cluster is recommended).

### Short Reproducility Study

For convenience the fully preprocessed dataset used in the paper is provided here **TODO**. Please follow the instructions in **TODO** for reproducing the results in the paper with the exact same data and method.

### Full Replication

In this option it is possible to apply the contrast method to different source data and/or different target relations. However this requires (much) more effort and computational resources:

- This study uses two source for the biomedical literature:
    - [PubTatorCentral](https://www.ncbi.nlm.nih.gov/research/pubtator/) conveniently provides Medline/PMC data after annotation and disambiguation. This data still needs to be converted to TDC format and pre-processed using The [TDC Tools code](https://github.com/erwanm/tdc-tools).
    - The raw Medline/PMC data can be converted to TDC and disambiguated using the following tools:
        - [This fork of the Knowedge Discovery (KD) repository](https://github.com/erwanm/knowledgediscovery) (The [original code](https://github.com/jakelever/knowledgediscovery) was made by Jake Lever)
        - The in-house disambiguation code ["KD Data Tools"](https://github.com/erwanm/kd-data-tools)
        - The [TDC Tools code](https://github.com/erwanm/tdc-tools).

## Software Requirements

- This code requires R and a few R libraries: 
    - `reshape2`
    - `ggplot2`
    - `plyr`
    
The code can be loaded in the R interpreter with:

```{r}
source('contrast-experiments.R')
```

## Hardware Requirements

The [full replication](#full-replication) requires massive resources for computing the source data (see documentation of the required repositories), and at least 32 GB RAM for processing the data from scratch with the R code. 

# Preparing data

- Note 1: some of the commands below are run with `system.time()` in order to show how long they take to execute. This is optional, of course.
- Note 2: in the following we present the simplest way to reproduce the experiments. Most of the functions accept optional arguments which may be useful for alternative tasks or data.
 
## Raw frequency data

The input data is made of at least one of the two sources:

- PubTator Central (PTC), obtained with [TDC Tools code](https://github.com/erwanm/tdc-tools). 
- Knowedge Discovery (KD), obtained with [my fork of the Knowedge Discovery (KD) repository](https://github.com/erwanm/knowledgediscovery), [KD Data Tools](https://github.com/erwanm/kd-data-tools) and [TDC Tools code](https://github.com/erwanm/tdc-tools).

The R code expects the data directory structure as: `<data dir>/<dataset>/<indiv|joint>/<level>/<view>/<year>[.total]` where:

- `<dataset>` is the id of the data, e.g. `PTC` or `KD`.
- subdirectories `indiv` and `joint` contain respectively the individual (resp. joint) frequencies of the concepts (resp. concepts relations) depending on the view and level, as computed by [TDC Tools code](https://github.com/erwanm/tdc-tools)).

```{r}
system.time(raw<-loadData(verbose=FALSE))
```

- Note: the PTC concepts are expected to be read as `<id>@<type>`; the `@<type>` suffix is removed by default.

`raw` is a list made of three dataframes `indiv`, `joint` and `total`:

```{r}
colnames(raw$indiv)
colnames(raw$joint)
colnames(raw$total)
```

## Target Concepts and Discoveries

### Target Concepts

By default individual target concepts are provided in the file `data/targets.list` which can be loaded as:

```{r}
targets <- loadTargetsList()
kable(targets)
```

The content should contain for every target the corresponding Mesh descriptor and UMLS concept id (CUI).



### Target Discoveries

By default the pairs of concepts representing the target discoveries are provided in the file `data/discoveries.tsv` which can be loaded as:

```{r}
discoveries <- loadDiscoveries()
kable(discoveries)
```

### Preparing Target Pairs

The individual target ids and discovery relations are combined in a dataframe which provides the relevant id (Mesh or UMLS) depending on the source dataset:

```{r}
targetPairs <- preprocessDiscoveries(discoveries,targets)
kable(targetPairs)
```


## Determine a range of years for every discovery

- Note: the steps below are needed only for the purpose of evaluating the method using past discoveries as gold standard. In an exploratory setting one would simply aggregate all the years for which data is available.

### Filtering the raw data

```{r}
targetPairsJointData <- filterJointPairs(targetPairs,raw$joint)
kable(targetPairsJointData[sample(1:nrow(targetPairsJointData), 6),])
```

### Calculating the Range of Years Before Discovery

The function below calculates the first year of the consecutive sequence where the two concepts have at least one occurrence every year (assumed to represent the "discovery"). It returns for every relation the range of years *before* this "discovery year": by default the start year is arbitrarily set to 1950, and the end year is the year just before the "discovery year".

```{r}
targetRanges <- selectYearRange(targetPairsJointData)
kable(targetRanges)
```


### Aggregating frequencies across years

This step sums the individual, joint and total frequencies in the `raw` list across the years specified by `targetRanges` for every required range of years. 

```{r}
system.time(aggregated<-aggregateFullDataAcrossYears(raw, targetRanges))
```

`aggregated` is a list made of 3 dataframes `indiv`, `joint` and `total`.

## Preparing the final dataset

The following step integrates the 3 dataframes together so that each row contains all the relevant frequencies for the corresponding pair of concepts.

```{r}
system.time(integrated<-integratePairsDataByYearRange(aggregated))
kable(integrated[sample(1:nrow(integrated),6),])
```


Finally the dataframe is reformated for convenient access by pair (target concept, related concept): for every target concept in `targetPairs` and any relation (A,B) in `aggregated`, the target (A or B) is placed as the first concept. If both A and B are targets, rows are added to represent the two cases. This way from the output dataframe a full list of relations can be selected for any specific target.


```{r}
lbd_data<-reformatRelationsByTarget(aggregated, targetPairs)
kable(lbd_data[sample(1:nrow(lbd_data),6),])
```

## Saving the final dataset

```{r}
write.table(lbd_data, 'lbd_data.tsv',sep='\t',quote = FALSE,row.names=FALSE)
```
